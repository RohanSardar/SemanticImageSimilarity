# üîç Semantic Image Search Engine

> A high-performance, multimodal search engine powered by **OpenAI CLIP** and **Qdrant** Vector Database.

![Python](https://img.shields.io/badge/Python-3.13+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-Latest-green.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-Latest-FF4B4B.svg)
![Docker](https://img.shields.io/badge/Docker-Enabled-2496ED.svg)

## üìå Overview

This project implements a **semantic search engine** that allows users to find images using **natural language descriptions** (e.g., *"a peaceful mountain lake at sunset"*) or by uploading a **reference image**. 

Unlike traditional keyword search, this system understands the *content* and *context* of images using high-dimensional vector embeddings generated by the **CLIP (Contrastive Language-Image Pre-training)** model.

## üèóÔ∏è System Architecture

![System Architecture](flow.png)

The application follows a modern microservices pattern:
1.  **Frontend (Streamlit)**: Lightweight UI for user interaction and result visualization.
2.  **Backend (FastAPI)**: Handles model inference (CPU/GPU) and coordinates with the database.
3.  **Database (Qdrant)**: Stores 512-dimensional vector embeddings and metadata.

---

## üöÄ Getting Started

### 1Ô∏è‚É£ Prerequisites
Before running the project, ensure you have the following installed:
- **Docker Desktop** (Required to run Qdrant and the Microservices).
- **Python 3.13+** (For running local setup scripts).
- **Unsplash Lite Dataset**:
    - Download the [Unsplash Lite Dataset](https://unsplash.com/data) (25k images) freely available online.
    - Extract it to a folder on your machine (e.g., `Downloads/unsplash-lite`).

### 2Ô∏è‚É£ Configuration
You must update the file paths to point to your downloaded dataset.

1.  **Update `docker-compose.yml`**:
    Change the volume path under `services: -> backend:` and `services: -> frontend:` to match your local image folder.
    ```yaml
    volumes:
       - C:/Path/To/Your/unsplash-lite:/data/images:ro
    ```

2.  **Update `qdrant_setup.py`**:
    Update the `IMAGE_FOLDER` variable at the top of the file:
    ```python
    IMAGE_FOLDER = r"C:\Path\To\Your\unsplash-lite"
    ```

### 3Ô∏è‚É£ Installation & Run
1.  **Clone the repository**:
    ```bash
    git clone https://github.com/yourusername/semantic-image-search.git
    cd semantic-image-search
    ```

2.  **Start the Services**:
    Run the following command to build and start the Docker containers:
    ```bash
    docker-compose up --build
    ```
    *Wait until you see the logs `Uvicorn running on http://0.0.0.0:8000` and `Streamlit ... http://0.0.0.0:8501`.*

### 4Ô∏è‚É£ Data Ingestion (First Run Only)
Once the Docker containers are running (specifically the Qdrant database on port 6333), you need to populate the database with your images.

**Open a new terminal window** and run:
```bash
# Make sure you have the dependencies installed locally first
pip install -r requirements.txt

# Run the ingestion script
python qdrant_setup.py
```
### 5Ô∏è‚É£ Access the Application
- **Frontend (UI)**: [http://localhost:8501](http://localhost:8501) - *Open this in your browser to use the search engine.*
- **Backend (API Docs)**: [http://localhost:8000/docs](http://localhost:8000/docs) - *Swagger UI for testing API endpoints.*
- **Qdrant Dashboard**: [http://localhost:6333/dashboard](http://localhost:6333/dashboard) - *View your vector collection status.*

---

## üíæ Data Persistence & Production Notes

This project uses **Docker Bind Mounts** (`./qdrant_data:/qdrant/storage`) for simplicity and portability. This ensures:
1.  **Zero-Config**: You can clone the repo and run it without setting up external database clouds.
2.  **Easy Backup**: All your vector data is visible in the `qdrant_data` folder on your host machine.

> **Note for Production**: In a large-scale enterprise environment, this would typically be replaced by **Docker Named Volumes** (for better I/O performance) or a **Managed Vector Database** (like Qdrant Cloud or AWS RDS) to handle backups and high availability.

---

## üõ†Ô∏è Tech Stack

| Component | Technology | Description |
| :--- | :--- | :--- |
| **Model** | [OpenAI CLIP](https://github.com/openai/CLIP) | Multimodal (Text-to-Image) Embeddings |
| **Backend** | [FastAPI](https://fastapi.tiangolo.com/) | High-performance Async API |
| **Frontend** | [Streamlit](https://streamlit.io/) | Data Science & ML Web Interface |
| **Database** | [Qdrant](https://qdrant.tech/) | Vector Search Engine (Running in Docker) |
| **DevOps** | Docker Compose | Container Orchestration |

---

## üìà Performance
- **Dimension**: 512
- **Search Latency**: < 50ms (Approx, depends on hardware)
- **Model**: ViT-B/16 (Running on Python 3.13)
